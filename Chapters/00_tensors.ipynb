{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d756b6e3",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b245f7",
   "metadata": {},
   "source": [
    "##### Notes: \n",
    "`torch.Tensor` - A class constructor that creates a tensor of a specified size, which is uninitialized by default and defaults to a float32 datatype.\n",
    "\n",
    "`torch.tensor()` - A factory function that creates a tensor from existing data, which is always initialized and infers the datatype from the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "760725ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828fe035",
   "metadata": {},
   "source": [
    "### Initializing and Creating a Tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38fa1ca",
   "metadata": {},
   "source": [
    "PyTorch tensors are created using `torch.Tensor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7636f6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0ae92a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bb2f732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor back as python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d077729b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectors\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16597f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8c8ca38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c99be55",
   "metadata": {},
   "source": [
    "**MATRIX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62593284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX = torch.tensor([[7, 8],\n",
    "                       [9, 10]])\n",
    "MATRIX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81d9d593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a564d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ca61fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf641e70",
   "metadata": {},
   "source": [
    "**TENSOR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9729fc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b367f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa97db9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90ce3101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0045, 0.6852, 0.5535, 0.9865],\n",
       "        [0.3760, 0.8978, 0.6018, 0.6894],\n",
       "        [0.3110, 0.8157, 0.7050, 0.4586]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(size=(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8b449ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6885, 0.9362, 0.0493, 0.3285],\n",
       "        [0.2260, 0.0215, 0.0738, 0.0597],\n",
       "        [0.8451, 0.9234, 0.9524, 0.7914]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b5f08c",
   "metadata": {},
   "source": [
    "**Random Tensors**\n",
    "\n",
    "Why random tensors?\n",
    "\n",
    "Random tensors are important because the way neural network learn it that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
    "\n",
    "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9985e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1029, 0.2193, 0.4258, 0.5353],\n",
       "        [0.8592, 0.0591, 0.5978, 0.4943],\n",
       "        [0.6799, 0.6051, 0.6330, 0.8697]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3, 4)\n",
    "# random_tensor = torch.rand(1, 10 , 10)\n",
    "# random_tensor = torch.rand(1, 3, 4)\n",
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f1743a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(random_tensor.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e73138e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(3, 224, 224)) # color channel, heigh, width\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3a3909",
   "metadata": {},
   "source": [
    "### Zeros and Ones Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07a437dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d70f01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(3, 4)\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a819e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad59de",
   "metadata": {},
   "source": [
    "**Directly from data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f275ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ff21ca",
   "metadata": {},
   "source": [
    "**From a NumPy Array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6760127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bb1c44",
   "metadata": {},
   "source": [
    "**From another Tensor**\n",
    "\n",
    "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb09c145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.1497, 0.9118],\n",
      "        [0.9367, 0.2235]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395f9726",
   "metadata": {},
   "source": [
    "**With Random or constant values**\n",
    "\n",
    "shape is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5ceb894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.1266, 0.5012, 0.2305],\n",
      "        [0.0656, 0.0513, 0.1110]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920e9c4c",
   "metadata": {},
   "source": [
    "### Creating a range of tensor and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50e9111a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use torch.arange()\n",
    " \n",
    "# one_to_ten = torch.arange(0, 10)\n",
    "one_to_ten = torch.arange(start=1, end=11, step=1)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed522e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensors like\n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7d20e7",
   "metadata": {},
   "source": [
    "### Tensor Datatypes\n",
    "\n",
    "**Note:** Tensor datatypes is one of the 3 big errors you'll run into with PyTorch & deep learning: \n",
    "\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a5269b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                            #    dtype=torch.float16, \n",
    "                               dtype=None, # what datatype is the tensor (e.g. float32 or float16)\n",
    "                               device=None, # What device is your tensor on\n",
    "                               requires_grad=False # Whether or not to track gradients\n",
    "                               ) \n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6f1c42fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3a14cd06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9f550c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor * float_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2768ced9",
   "metadata": {},
   "source": [
    "### Attributes of a Tensor\n",
    "\n",
    "Tensor attributes describe their shape, datatype, and the device on which they are stored.\n",
    "\n",
    "1. Tensors not right datatype - to get datatype from a tensor, use `tensor.dtype`\n",
    "2. Tensors not right shape - to get shape from a tensor, use `tensor.shape`\n",
    "3. Tensors not on the right device - to get device from a tensor, use `tensor.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd59cd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee125b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6914, 0.8281, 0.4172, 0.1646],\n",
       "        [0.1191, 0.6375, 0.4355, 0.7285],\n",
       "        [0.2973, 0.3286, 0.1865, 0.6102]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = torch.rand(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ac4b8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function Tensor.size>, torch.Size([3, 4]), torch.Size([3, 4]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.size, some_tensor.size(), some_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e9074d",
   "metadata": {},
   "source": [
    "### Operations on Tensors\n",
    "\n",
    "Over 1200 tensor operations, including arithmetic, linear algebra, matrix manipulation (transposing, indexing, slicing), sampling and more are comprehensively described [here](https://docs.pytorch.org/docs/stable/torch.html).\n",
    "\n",
    "By default, tensors are created on the **CPU**. We need to explicitly move tensors to the accelerator using `.to` method, but first you need to check the availability of *accelerator*.\n",
    "\n",
    "Moving large tensors across devices can be expensice in terms of time and memory!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04d93f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4252, 0.5038, 0.6527, 0.3586],\n",
      "        [0.9153, 0.5130, 0.5783, 0.5227],\n",
      "        [0.5210, 0.7752, 0.2019, 0.0740]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# We move our tensor to the current accelerator if available\n",
    "if torch.accelerator.is_available():\n",
    "    tensor = tensor.to(torch.accelerator.current_accelerator())\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c41b6f0",
   "metadata": {},
   "source": [
    "**Few Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5028fab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7831, 0.9448, 0.5845],\n",
      "        [0.4244, 0.3711, 0.2625]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "\n",
    "tensor = torch.rand(shape)\n",
    "print(tensor)\n",
    "\n",
    "# Operations\n",
    "print(torch.is_tensor(tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97df679",
   "metadata": {},
   "source": [
    "**Standard Numpy-Like Indexing and Slicing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3257dc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(5,4)\n",
    "print(f\"First Row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b22c55f",
   "metadata": {},
   "source": [
    "**Joining Tensors**\n",
    "\n",
    "understand this a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1056361e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7751a014",
   "metadata": {},
   "source": [
    "**Arithmetic Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1b99304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "y1:\n",
      " tensor([[3., 3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3., 3.]])\n",
      "y2:\n",
      " tensor([[3., 3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3., 3.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This Computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
    "# ``tensor.T` returns the Transpose of a tensor\n",
    "print(tensor)\n",
    "\n",
    "y1 = tensor @ tensor.T\n",
    "print(f\"y1:\\n {y1}\")\n",
    "\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "print(f\"y2:\\n {y2}\")\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cf8483",
   "metadata": {},
   "source": [
    "**Single-element Tensors**\n",
    "\n",
    "if you have one-element tensor, for example by aggregating all values of a tensor into one value, you can convert it to a Python numerical value using `item()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2cb998f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3895d88",
   "metadata": {},
   "source": [
    "**In-Place Operations** \n",
    "\n",
    "Operations that store the result into the operand are called in-place. They are denoted by a `_` suffix. for example: `x.copy_(y)`, `x.t_()`, will change `x`.\n",
    "\n",
    "**Note**: \n",
    "In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss of history. Hence, their use is discouraged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d22e90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{tensor} \\n\")\n",
    "tensor.add_(5)\n",
    "# tensor.sub_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e4c186",
   "metadata": {},
   "source": [
    "### Bridge with NumPy\n",
    "\n",
    "Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other.\n",
    "\n",
    "- Data in numpy, want in PyTorch tensor -> `torch.from_numpy(ndarray)`\n",
    "- PyTorch tensor -> Numpy -> `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6049d0",
   "metadata": {},
   "source": [
    "**Tensor to NumPy array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e85de36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensort: tensor([1., 1., 1., 1., 1.])\n",
      "array: [1. 1. 1. 1. 1.]\n",
      "Datatype of numpy array: float32\n",
      "Datatype of tensor: torch.float32\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(5)\n",
    "print(f\"tensort: {tensor}\")\n",
    "\n",
    "numpy_array = tensor.numpy()\n",
    "print(f\"array: {numpy_array}\")\n",
    "\n",
    "tensor, numpy_array\n",
    "\n",
    "print(f\"Datatype of numpy array: {numpy_array.dtype}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e6f9b0",
   "metadata": {},
   "source": [
    "A change in the tensor reflects in the NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "833c4664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor: tensor([2., 2., 2., 2., 2.])\n",
      "array: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "tensor.add_(1)\n",
    "print(f\"tensor: {tensor}\")\n",
    "print(f\"array: {numpy_array}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c988af3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 3., 3., 3., 3.]), array([2., 2., 2., 2., 2.], dtype=float32))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor + 1\n",
    "tensor, numpy_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e0132d",
   "metadata": {},
   "source": [
    "**NumPy array to Tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16c81b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 1., 1., 1.]),\n",
       " tensor([1., 1., 1., 1., 1.], dtype=torch.float64))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.ones(5)\n",
    "t = torch.from_numpy(np_array) # warning : By default, NumPy arrays are created with the datatype float64 and if you convert it to a PyTorch tensor, it'll keep the same datatype (as above).\n",
    "# t = torch.from_numpy(np_array).type(torch.flaot32)\n",
    "np_array, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18a4bb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of numpy array: float64\n",
      "Datatype of tensor: torch.float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Datatype of numpy array: {np_array.dtype}\")\n",
    "print(f\"Datatype of tensor: {t.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80616b13",
   "metadata": {},
   "source": [
    "change in the NumPy Array reflects in the Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04eedeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "np_array: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(np_array, 1, out=np_array)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"np_array: {np_array}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "004bb272",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m n = \u001b[43mn\u001b[49m + \u001b[32m1\u001b[39m\n\u001b[32m      2\u001b[39m n, t\n",
      "\u001b[31mNameError\u001b[39m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "n = n + 1\n",
    "n, t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0329d96f",
   "metadata": {},
   "source": [
    "### Manipulating Tensors ( tensor opertions ) \n",
    "\n",
    "Tensor Opertions include:\n",
    "- Addition\n",
    "- Substraction\n",
    "- Multiplication (element-wise)\n",
    "- Division\n",
    "- Matrix multiplication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9945e8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Tensor and add 10 to it\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0871c38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply tensor by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e707dbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d62f120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substract 10\n",
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbd0d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorch in-built functions\n",
    "torch.mul(tensor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e82f24d",
   "metadata": {},
   "source": [
    "**MATRIX MULTIPLICATION**\n",
    "\n",
    "https://www.matrixmultiplication.xyz\n",
    "\n",
    "Two main ways of performing multiplication in neural networks and deeplearning\n",
    "\n",
    "1. Element-wise multiplication \n",
    "2. Matrix Multiplication ( dot product )\n",
    "\n",
    "The main two rules for matrix multiplication to remember are:\n",
    "\n",
    "1. The**inner dimensions** must match:\n",
    "- (3, 2) @ (3, 2) won't work\n",
    "- (2, 3) @ (3, 2) will work\n",
    "- (3, 2) @ (2, 3) will work\n",
    "\n",
    "2. The resulting matrix has the shape of the **outer dimensions**:\n",
    "- (2, 3) @ (3, 2) -> (2, 2)\n",
    "- (3, 2) @ (2, 3) -> (3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe83d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3965, 0.6830],\n",
       "        [0.2702, 0.3799]])"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.matmul(torch.rand(2, 3), torch.rand(2, 3))\n",
    "torch.matmul(torch.rand(2, 3), torch.rand(3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be61d527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element wise\n",
    "print(tensor, \"*\" ,tensor)\n",
    "print(f\"Equals: {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db51ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7fd12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71738b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication by hand\n",
    "1*1 + 2*2 + 3*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b548a417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1.01 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Matrix multiplication by hand \n",
    "# (avoid doing operations with for loops at all cost, they are computationally time expensive)\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "  value += tensor[i] * tensor[i]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9382c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27614f06",
   "metadata": {},
   "source": [
    "### One of the most common errors in deep learning: Shape errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc274edd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[391]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      6\u001b[39m tensor_B = torch.tensor([[\u001b[32m7\u001b[39m, \u001b[32m10\u001b[39m],\n\u001b[32m      7\u001b[39m                          [\u001b[32m8\u001b[39m, \u001b[32m11\u001b[39m], \n\u001b[32m      8\u001b[39m                          [\u001b[32m9\u001b[39m, \u001b[32m12\u001b[39m]])\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# torch.mm is the same as torch.matmul (it's and alias)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# thorws error\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shape for matrix multiplication\n",
    "tensor_A = torch.tensor([[1, 2,],\n",
    "                         [3, 4],\n",
    "                         [5, 6]])\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]])\n",
    "\n",
    "# torch.mm is the same as torch.matmul (it's and alias)\n",
    "torch.matmul(tensor_A, tensor_B) # thorws error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7009af",
   "metadata": {},
   "source": [
    "To fix tensor shape issues, we can manipulate the shape of one of our tensor using a **transpose**.\n",
    "A **transpose** switches the axes or dimensions of a given tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152ea7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_B, tensor_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d58e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_B.T, tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83761e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The matrix multipication operation works when tensor_B is transposed\n",
    "\n",
    "# The operation works when tensor_B is transposed\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\") \n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
    "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
    "print(\"Output:\\n\")\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output) \n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4384dd94",
   "metadata": {},
   "source": [
    "### Finding the min, max, mean, sum, etc (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9608b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tensor \n",
    "x = torch.arange(1, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a1eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the min\n",
    "torch.min(x), x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaf13e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the max\n",
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9e92cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean - note: the torch.mean() function requires a tensor of float32 datatype to work\n",
    "# torch.mean(x.type(torch.float32)), x.mean() # datatype error coz its long\n",
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f551bbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the sum\n",
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d37cf38",
   "metadata": {},
   "source": [
    "### Finding the positional min and max\n",
    "\n",
    "You can also find the index of a tensor where the max or minimum occurs with `torch.argmax()` and `torch.argmin()` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7259734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a84ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the position in tensor that has teh minimum value with argmin() -> return index  position of target tensor where the minimum value occurs\n",
    "x.argmin(), x.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa329228",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0], x[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34172ee",
   "metadata": {},
   "source": [
    "### Reshaping, Stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "- Reshaping - Reshaping an input tensor to a detined snape\n",
    "\n",
    "- View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "\n",
    "- Stacking-combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
    "\n",
    "- Squeeze - removes all 1 dimensions from a tensor\n",
    "Unsqueeze add a 1 dimension to a target tensor\n",
    "\n",
    "- Permute - Return a view of the input with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eca664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a tensor\n",
    "import torch \n",
    "x = torch.arange(1., 10.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c07c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1, 9) # should be 9 by multiplying   \n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa56f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the view \n",
    "z = x.view(1, 9)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589ddde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing z changes x ( because a view of a tensor shares the same memory as the original input)\n",
    "z[:, 0] =  5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64a70b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f333cf",
   "metadata": {},
   "source": [
    "**`torch.squeeze()`** - Remove all single dimensions from a target tensor\n",
    "\n",
    "To do so you can use torch.squeeze() (I remember this as squeezing the tensor to only have dimensions over 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462af8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "# Remove extra dimension from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5b916c",
   "metadata": {},
   "source": [
    "**`torch.unsqueeze()`** - adds a single dimension to a target tensor at a specific dim ( dimension )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175f97fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Previous tensor: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "## Add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca8c19d",
   "metadata": {},
   "source": [
    "**`torch.permute()`** - rearrange the dimensions of a target tensor in specified order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346331b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_original = torch.rand(size=(3, 224, 224)) # [heigh, width, color channel]\n",
    "x_original = torch.rand(size=(224, 224, 3)) # [heigh, width, color channel]\n",
    "\n",
    "# Permute the original tensor to rearrange the axis (or dim) order\n",
    "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "# View shares the same memory as the original tensor\n",
    "print(f\"Previous shape: {x_original}\")\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted}\")  \n",
    "print(f\"New shape: {x_permuted.shape}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f84719",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_original[0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3784a543",
   "metadata": {},
   "source": [
    "### Indexing( selecting data from tensors)\n",
    "Indexing with PyTorch is similar to indexing with nump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87607a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor\n",
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e35957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's index on our new tensor\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cae341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's index on the middle bracket (dim=1)\n",
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6aaa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's index on the most inner bracket( last dimension )\n",
    "x[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96df0d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use \":\" to select \"all\" of a target dimension\n",
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f214c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use \":\" to select \"all\" of a target dimension\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a83928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all values of the 0 dimension but only the 1 index value of 1st and 2nd dimension\n",
    "print(x)\n",
    "print(x[:, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdbfd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0:0:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55348528",
   "metadata": {},
   "source": [
    "### Reproducibility (Trying to take random out of random)\n",
    "\n",
    "**Extra Resourc** \n",
    "https://docs.pytorch.org/docs/stable/notes/randomness.html#reproducibility\n",
    "\n",
    "In short how a neural network learns: \n",
    " \n",
    "`start with random numbers -> tensor operations -> update random numbers to try and make better representations of the data -> again -> again... `\n",
    "\n",
    "to reduce the randomness in neural network and PyTorch comes the concept of a random seed.\n",
    "\n",
    "Essentially what the random seed does in \"flavour\" the randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb56bd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create two random tensor\n",
    "\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_A == random_tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85f67dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Let's make some random but reproducible tensors\n",
    "import torch\n",
    "\n",
    "# Set the random seed\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C == random_tensor_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aa68df",
   "metadata": {},
   "source": [
    "### Accessing a GPU\n",
    "\n",
    "`nvidia-smi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4d486007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep  7 13:56:30 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.52                 Driver Version: 576.52         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   43C    P5              5W /   75W |     733MiB /   4096MiB |     34%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            4872    C+G   D:\\Hawk\\cursor\\Cursor.exe             N/A      |\n",
      "|    0   N/A  N/A            5588    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A            5880    C+G   ...IA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A            6072    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A            6424    C+G   ...Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A            6696    C+G   ...Browser\\Application\\brave.exe      N/A      |\n",
      "|    0   N/A  N/A            7760    C+G   ...em32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A            9712    C+G   ...indows\\System32\\ShellHost.exe      N/A      |\n",
      "|    0   N/A  N/A           10524    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           10944    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           11292    C+G   ...2txyewy\\CrossDeviceResume.exe      N/A      |\n",
      "|    0   N/A  N/A           14588    C+G   ...App_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A           15156    C+G   ...IA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           16420    C+G   ...0.3405.125\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           17836    C+G   ...ntrolPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A           18004    C+G   ...mba6cd70vzyy\\ArmouryCrate.exe      N/A      |\n",
      "|    0   N/A  N/A           18840    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           20860    C+G   ...Browser\\Application\\brave.exe      N/A      |\n",
      "|    0   N/A  N/A           23048    C+G   ...AcrobatNotificationClient.exe      N/A      |\n",
      "|    0   N/A  N/A           25008    C+G   ...Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A           26808      C   ..._qbz5n2kfra8p0\\python3.11.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e26b671d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if GPU driver and CUDA is enabled and accessible by pytorch.\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44f9efd",
   "metadata": {},
   "source": [
    "**Note**: In PyTorch, it's best practice to write device agnostic code. This means code that'll run on CPU (always available) or GPU (if available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c2e94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44862db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94597412",
   "metadata": {},
   "source": [
    "### 3. Putting tensors (and models on the GPU)\n",
    "\n",
    "The reason we want our tensor/models on the GPU is because using GPU results in faster computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7ab582d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor (default on the CPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Tensor not on GPU \n",
    "print(tensor, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4462f739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move tensor to GPU (if availabel)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c10d458",
   "metadata": {},
   "source": [
    "### 4. Moving tensors back to the CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ccd2877",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# If tensor is on GPU, can't transform it to NumPy\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtensor_on_gpu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# If tensor is on GPU, can't transform it to NumPy\n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1a53abd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To fix the CPU tensor with NumPy issue, we can first set it to CPU\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b034a248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
